{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38d7469a",
   "metadata": {},
   "source": [
    "# 참고자료\n",
    "\n",
    "https://keras.io/examples/vision/oxford_pets_image_segmentation/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532d3443",
   "metadata": {},
   "source": [
    "# 환경설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b02d366",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7ae193",
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip /content/drive/MyDrive/dataset/dataset.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b1ccb0",
   "metadata": {},
   "source": [
    "# Chapter 1: Semantic Segmentation 이해하기\n",
    "\n",
    "- https://fullstackdeeplearning.com/spring2021/lecture-2b/\n",
    "- https://vision-explorer.allenai.org\n",
    "- Classification, Object Detection, Semantic Segmentation의 차이 (입력과 출력이 무엇일까요?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef2c5ca",
   "metadata": {},
   "source": [
    "# Chapter 2: QGIS로 데이터셋 만들기\n",
    "\n",
    "- QGIS로 road_polygon.shp, orthophoto_5179.tif 열기\n",
    "- 래스터화 (벡터를 래스터로)\n",
    "- 타일 재생성 (-of PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bddb03",
   "metadata": {},
   "source": [
    "# Chapter 3: TensorFlow로 학습시키기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5dca6ec",
   "metadata": {},
   "source": [
    "필요한 패키지 로드하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42eaf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import optimizers, losses, layers, Input, Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9f6dbc",
   "metadata": {},
   "source": [
    "데이터셋 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f212ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _replace_folder_name(src_img_fpath, folder_name):\n",
    "    dst_img_fpath = bytes.decode(src_img_fpath.numpy())\n",
    "    dst_img_fpath = Path(dst_img_fpath).parts\n",
    "    dst_img_fpath = list(dst_img_fpath)\n",
    "    dst_img_fpath[-2] = bytes.decode(folder_name.numpy())\n",
    "    dst_img_fpath = str(Path(*dst_img_fpath))\n",
    "    return dst_img_fpath\n",
    "\n",
    "\n",
    "def _parse_image(a_fpath, target_size, multiclass):\n",
    "    # Create file path for B and cmap using a_fpath\n",
    "    c_fpath = tf.py_function(_replace_folder_name, [a_fpath, \"cmap\"], tf.string)\n",
    "\n",
    "    # Read files\n",
    "    a_img = tf.io.read_file(a_fpath)\n",
    "    c_img = tf.io.read_file(c_fpath)\n",
    "\n",
    "    # Decode files\n",
    "    a_img = tf.image.decode_png(a_img, channels=3)\n",
    "    c_img = tf.image.decode_png(c_img, channels=1)\n",
    "\n",
    "    # Resize images\n",
    "    a_img = tf.image.resize(a_img, target_size)\n",
    "    c_img = tf.image.resize(c_img, target_size)\n",
    "\n",
    "    # Normalize images [0, 255] to [-1.0, 1.0]\n",
    "    a_img = tf.cast(a_img, tf.float32) / 127.5 - 1\n",
    "\n",
    "    # 255로 나눈 후 int8로 타입캐스팅 (int여야 SparseCatecoricalCrossentropy 적용 시 문제 없음)\n",
    "    c_img = tf.cast(c_img / 255, tf.int8)\n",
    "\n",
    "    return a_img, c_img\n",
    "\n",
    "\n",
    "def get_dataset(\n",
    "    dataset_dir, batch_size, target_size=(256, 256), shuffle=True, multiclass=False\n",
    "):\n",
    "    a_file_pattern = os.path.join(dataset_dir, \"A/*.png\")\n",
    "    ds = tf.data.Dataset.list_files(file_pattern=a_file_pattern, shuffle=shuffle)\n",
    "    ds = ds.map(lambda x: _parse_image(x, target_size, multiclass))\n",
    "    ds = ds.batch(batch_size)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fec1039",
   "metadata": {},
   "source": [
    "모델 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de0fdb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(img_size, num_classes):\n",
    "    inputs = Input(shape=img_size + (3,))\n",
    "\n",
    "    ### [First half of the network: downsampling inputs] ###\n",
    "\n",
    "    # Entry block\n",
    "    x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    previous_block_activation = x  # Set aside residual\n",
    "\n",
    "    # Blocks 1, 2, 3 are identical apart from the feature depth.\n",
    "    for filters in [64, 128, 256]:\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "\n",
    "        # Project residual\n",
    "        residual = layers.Conv2D(filters, 1, strides=2, padding=\"same\")(\n",
    "            previous_block_activation\n",
    "        )\n",
    "        x = layers.add([x, residual])  # Add back residual\n",
    "        previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "    ### [Second half of the network: upsampling inputs] ###\n",
    "\n",
    "    for filters in [256, 128, 64, 32]:\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.UpSampling2D(2)(x)\n",
    "\n",
    "        # Project residual\n",
    "        residual = layers.UpSampling2D(2)(previous_block_activation)\n",
    "        residual = layers.Conv2D(filters, 1, padding=\"same\")(residual)\n",
    "        x = layers.add([x, residual])  # Add back residual\n",
    "        previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "    # Add a per-pixel classification layer\n",
    "    outputs = layers.Conv2D(num_classes, 3, activation=\"softmax\", padding=\"same\")(x)\n",
    "\n",
    "    # Define the model\n",
    "    model = Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f90f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model((256, 256,), 2)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f4c6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = get_dataset(\"dataset\", 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6d4fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=1e-4),\n",
    "    loss=losses.SparseCategoricalCrossentropy(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077c4eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(ds, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62dd7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.predict(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb4e4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(result[133][:, :, 1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
